{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resampling, finding the subjects that aren't included in matlab, making mean image, making efields and smoothing, gdnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1ff260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "from nilearn.image import load_img\n",
    "from nilearn.image import math_img\n",
    "from nilearn.image import resample_to_img\n",
    "from nilearn.image import smooth_img\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc20c682",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#resample to mni: interpolation nearest!!\n",
    "mni = load_img('/Users/jp1590/Documents/MATLAB/leaddbs/templates/space/MNI152NLin2009bAsym/t1.nii')\n",
    "files = os.listdir('/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Zone1/All_Resampled')\n",
    "for i in files:\n",
    "    if i.startswith('sub-3') or i.startswith('sub-4'):\n",
    "        sub = load_img(f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Zone1/All_Resampled/{i}')\n",
    "        sub_re = resample_to_img(sub,mni,interpolation='nearest')\n",
    "        nib.save(sub_re,f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Zone1/cing-sct-res/{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e15dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine which subjects are included in the python n-map and not matlab n-map\n",
    "files = os.listdir('/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Bilat/Binary/z1-2')\n",
    "mean_diff = load_img('/Volumes/Cingulate/Sweetspot_Seg/Outputs/binary_zones1-2/n-map_difference.nii.gz')\n",
    "ybocs_df = pd.read_csv('/Volumes/Cingulate/Sweetspot_Seg/All_YBOCS_Flip.csv')\n",
    "nosignif = []\n",
    "ids = []\n",
    "for i in files:\n",
    "    if i.startswith('sub'):\n",
    "        sub = load_img(f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Bilat/Binary/z1-2/{i}')\n",
    "        mask = math_img('img1*img2',img1=sub,img2=mean_diff)\n",
    "        masked_sub = mask.get_fdata()\n",
    "#         nib.save(mask,f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/mask/{i}')\n",
    "#         masked_sub = load_img(f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/mask/{i}').get_fdata()\n",
    "        values = np.sum(masked_sub)\n",
    "        nosignif.append(values)\n",
    "        ids.append(i)\n",
    "\n",
    "#export to dataframe    \n",
    "nosignif_df = pd.DataFrame(\n",
    "    {'ID':ids,\n",
    "    'Volume_Overlap':nosignif\n",
    "    })\n",
    "\n",
    "nosignif_combined_df = nosignif_df.merge(ybocs_df,how='left',left_on=['ID'],right_on=['ID'])\n",
    "nosignif_combined_df.to_csv('/Volumes/Cingulate/Sweetspot_Seg/Outputs/n-image_overlap.csv')\n",
    "\n",
    "#find which subjects have overlap from the csv and put them in new folder\n",
    "non_zero = nosignif_combined_df.loc[nosignif_combined_df['Volume_Overlap']!=0,:]\n",
    "\n",
    "for i in non_zero['ID']:\n",
    "    shutil.copyfile(f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Bilat/Binary/z1-2/{i}',f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/outliers/{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a94c2be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace binary segmentations with ybocs score\n",
    "df = pd.read_csv('/Volumes/Cingulate/Sweetspot_Seg/mean-image-ybocs.csv')\n",
    "df.dropna(subset=['Relative'], inplace=True)\n",
    "df.dropna(subset=['ID'], inplace=True)\n",
    "for i in df.index:\n",
    "    sub_id = (df['ID'][i])\n",
    "    sub = load_img(f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Zone1/All_Resampled/{sub_id}')\n",
    "    relative = df['Relative'][i] #change relative here with value to be put in the binary segmentations\n",
    "    threshold = math_img(f'np.where(img1==1,{relative},0)',img1=sub)\n",
    "    nib.save(threshold,f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Zone1/All_YBOCS_Value/{sub_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3f519c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: RuntimeWarning: divide by zero encountered in divide\n",
      "<string>:1: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "#divide n-map and ybocs to get mean image\n",
    "n = load_img('/Volumes/Cingulate/Sweetspot_Seg/Outputs/binary_zone1/n-map_zone1.nii.gz')\n",
    "y = load_img('/Volumes/Cingulate/Sweetspot_Seg/Outputs/binary_zone1/ybocs_sum.nii.gz')\n",
    "yb = math_img('img1/img2',img1=y,img2=n)\n",
    "nib.save(yb,'/Volumes/Cingulate/Sweetspot_Seg/Outputs/binary_zone1/mean_image.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a267b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replaces values in a nifti file\n",
    "def replace(path):\n",
    "    sub = load_img(f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Bilat/Weighted_80-100/z1-2/{i}')\n",
    "    sub_array = sub.get_fdata()\n",
    "    new_data = np.where(sub_array == 80, 10, sub_array) #change here values to replace\n",
    "    new_data = new_data.astype(np.int16)\n",
    "    new_img = nib.Nifti1Image(new_data, sub.affine, sub.header)\n",
    "    nib.save(new_img,f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Bilat/Weighted_10-100/z1-2/{i}')\n",
    "    return new_img\n",
    "    \n",
    "path = '/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Bilat/Weighted_80-100/z1-2'\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    if i.endswith('nii.gz'):\n",
    "        replace(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a80f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smooth segmentations gaussianly\n",
    "weighted = os.listdir('/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Weighted_10-100/z1-2')\n",
    "for i in weighted:\n",
    "    if i.endswith('.nii.gz'):\n",
    "        sub = load_img(f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Weighted_10-100/z1-2/{i}')\n",
    "        gaussian = smooth_img(sub,fwhm=4) #change threshold here\n",
    "        nib.save(gaussian,f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Weighted_10-100/Efields_Unmasked_4/{i[:-18]}_smooth_bilat_flip.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca39a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove excess in the efields by masking with the binary segmentations\n",
    "binary = os.listdir('/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Binary/z1-2')\n",
    "for i in binary:\n",
    "    if i.endswith('.nii'):\n",
    "        bina = load_img(f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Binary/z1-2/{i}')\n",
    "        efield = load_img(f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Weighted_10-100/Efields_Unmasked_4/{i[:-15]}_smooth_bilat_flip.nii')\n",
    "        mask = math_img('img1*img2',img1=bina,img2=efield)\n",
    "        nib.save(mask,f'/Volumes/Cingulate/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Weighted_10-100/Efields_Masked_4/{i[:-15]}_smooth_bilat_flip.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e85247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdnf one patient\n",
    "df = pd.DataFrame(columns=['ID','T1_or_Post','Inf_Date','Date_of_Image','Time_Since_Inf','path'])\n",
    "for i in os.listdir('/Volumes/Cingulate/GDNF/GD06_nii'):\n",
    "    if i.endswith('1_post.nii.gz'):\n",
    "        t1_or_post_value = 'post'\n",
    "    elif i.endswith('T1.nii.gz'):\n",
    "        t1_or_post_value = 'T1'\n",
    "    else:\n",
    "        t1_or_post_value = 'Infusion'\n",
    "\n",
    "    df.loc[len(df)] = {\n",
    "        'ID': 'GD06',\n",
    "        'path': f'/Volumes/Cingulate/GDNF/GD06_nii/{i}',\n",
    "        'Inf_Date': '20150729',\n",
    "        'Date_of_Image': int(i[0:8]),\n",
    "        'Time_Since_Inf': f'{int(i[0:4])-2015}y {int(i[5:6])-7}m',\n",
    "        'T1_or_Post': t1_or_post_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d7aa0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdnf all patients\n",
    "df = pd.DataFrame(columns=['ID', 'Inf_Date', 'Date_of_Image', 'Time_Since_Inf', 'T1_or_Post','path'])\n",
    "\n",
    "path = '/Volumes/Cingulate/GDNF'\n",
    "inf_date = None\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a subfolder\n",
    "        for i in os.listdir(folder_path):\n",
    "            if i.endswith('Infusion') or i.endswith('gz'):\n",
    "                if i.endswith('Infusion'):\n",
    "                    inf_date = i[0:8]\n",
    "                if i.endswith('1_post.nii.gz'):\n",
    "                    t1_or_post_value = 'post'\n",
    "                elif i.endswith('T1.nii.gz'):\n",
    "                    t1_or_post_value = 'T1'\n",
    "                elif i.endswith('Infusion'):\n",
    "                    t1_or_post_value = 'Infusion'\n",
    "                    inf_date = i[0:8]\n",
    "                else:\n",
    "                    t1_or_post_value = 'None'\n",
    "\n",
    "                df.loc[len(df)] = {\n",
    "                    'ID': folder[:-4],\n",
    "                    'path': os.path.join(folder_path, i),\n",
    "                    'Inf_Date': inf_date,\n",
    "                    'Date_of_Image': int(i[0:8]),\n",
    "                    'Time_Since_Inf': f'{int(i[0:4])-2015}y {int(i[5:6])-7}m', #need to update in csv with correct subtraction\n",
    "                    'T1_or_Post': t1_or_post_value\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b7b13e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix up time since infusion column\n",
    "ddf = pd.read_csv('/Volumes/Cingulate/GDNF/gdnf.csv')\n",
    "ddf['Time_Since_Inf'] = ddf.apply(lambda row: f'{(row[\"Date_of_Image\"] // 10000) - (row[\"Inf_Date\"] // 10000)}y {(row[\"Date_of_Image\"] // 100 % 100) - (row[\"Inf_Date\"] // 100 % 100)}m', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8374dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the volume of each lesion\n",
    "vol = []\n",
    "ids = []\n",
    "for i in os.listdir('/Volumes/Empty/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Binary/z1-2'):\n",
    "    if i.endswith('.nii'):\n",
    "        sub = load_img(f'/Volumes/Empty/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Binary/z1-2/{i}').get_fdata()\n",
    "        sub_vol = np.sum(sub)\n",
    "        vol.append(sub_vol)\n",
    "        ids.append(i)\n",
    "        \n",
    "df = pd.DataFrame(\n",
    "    {'ID':ids,\n",
    "    'Volume':vol\n",
    "})\n",
    "df.to_csv('/Volumes/Empty/Sweetspot_Seg/binary_vols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04168894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Volumes/Empty/Sweetspot_Seg/All_YBOCS_Flip_No_Volume.csv')\n",
    "for i in df['ID']:\n",
    "    df['ID'] = df['ID'].replace(i,f'/Volumes/Empty/Sweetspot_Seg/Sweetspot_Seg_All_Flipped/Weighted_50-100/Efields_Masked_1.5/{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a2602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
